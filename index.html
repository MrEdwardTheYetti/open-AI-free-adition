<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Browser AI (CPU)</title>
  <script type="module">
    import * as webllm from "https://esm.run/@mlc-ai/web-llm";

    let engine;

    async function init() {
      const status = document.getElementById("status");
      status.textContent = "Loading CPU modelâ€¦ (first time takes ~1 min)";

      engine = new webllm.MLCEngine({
        device: "cpu"   // ðŸ‘ˆ FORCE CPU
      });

      await engine.reload("TinyLlama-1.1B-Chat-v1.0-q4f16_1");

      status.textContent = "AI Ready (CPU Mode)";
    }

    async function ask() {
      const prompt = document.getElementById("prompt").value;
      const reply = await engine.chat.completions.create({
        messages: [{ role: "user", content: prompt }]
      });
      document.getElementById("out").textContent =
        reply.choices[0].message.content;
    }

    window.ask = ask;
    init();
  </script>
</head>

<body style="background:#111;color:#0f0;font-family:sans-serif">
  <h2>Browser AI (CPU / No GPU)</h2>
  <div id="status">Startingâ€¦</div>
  <textarea id="prompt" rows="4" style="width:100%"></textarea>
  <button onclick="ask()">Ask</button>
  <pre id="out"></pre>
</body>
</html>
